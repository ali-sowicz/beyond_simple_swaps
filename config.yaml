models:
  names:
    - meta-llama/Llama-3.2-1B-Instruct
    - meta-llama/Llama-3.2-3B-Instruct,
    - Qwen/Qwen2.5-1.5B-Instruct,
    - microsoft/Phi-3.5-mini-instruct
  huggingface_token: "YOUR_HUGGINGFACE_TOKEN"


run_experiment:
  gpu_id: 0 # Specify the GPU ID here
  batch_size: 25
  dataset_dir: "../eval_dynamic/data/dataset_dynamic/test"
  output_dir: "../eval_dynamic/output/output_results"
  prompt_type: "prompt_without_cot"  # or prompt_without_cot, prompt_few_shot
  subfolders:   # specify if you want to run experiment on all subfolders
    - basic_swap 
    - negations
    - overlap
    - rules

compute_accuracy:
  json_dir: "../eval_dynamic/output/output_results/prompt_without_cot" # prompt_with_cot or prompt_without_cot, prompt_few_shot

manual_correction:
  metadata_path: "../eval_dynamic/output/output_results/prompt_with_cot/evaluation_metadata.json"
  updated_metadata_path: "../eval_dynamic/output/output_results/prompt_with_cot/evaluation_metadata_updated.json"
  accuracy_output_path: "../eval_dynamic/output/output_results/prompt_with_cot/accuracy_summary.json"




